{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab513d8-5b21-4fa8-9d43-920df4532201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers datasets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd99ab23-7c66-4c69-a15d-698e0e81e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95179e7-b510-4bd6-b633-8737f8f7a567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b670858c81634fdbaa5b6e243a665864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "model_repo = \"facebook/dinov3-vits16-pretrain-lvd1689m\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_repo)\n",
    "backbone = AutoModel.from_pretrained(model_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08afd98-7b15-4b26-b053-53a7cb015eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_nsfwdataset, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd929d8-e287-4515-8ca3-8446f9266609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier model has 21.60M parameters (770 trainable)\n"
     ]
    }
   ],
   "source": [
    "class DinoV3Linear(nn.Module):\n",
    "    def __init__(self, backbone: AutoModel, hidden_size: int, num_classes: int, freeze_backbone: bool = True):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "            self.backbone.eval()\n",
    "\n",
    "        self.head = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.backbone(pixel_values=pixel_values)\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        cls = last_hidden[:, 0]\n",
    "        logits = self.head(cls)\n",
    "        return logits\n",
    "\n",
    "    def count_params(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return total_params, trainable_params\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "        \n",
    "# Setup Model\n",
    "hidden_size = getattr(backbone.config, \"hidden_size\", None)\n",
    "model = DinoV3Linear(backbone, hidden_size, num_classes=2, freeze_backbone=True).to(device) \n",
    "total_params, trainable_params = model.count_params()\n",
    "\n",
    "# Setup Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004)\n",
    "\n",
    "# Load Dataset\n",
    "ds_train, ds_test = load_nsfwdataset(processor, batch_size_train = 128)\n",
    "\n",
    "print(f\"classifier model has {total_params/1e6:.2f}M parameters ({trainable_params} trainable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daeb4cd6-4ff7-4f50-8db1-755b8c2dc8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 (epoch 0), loss 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test accuray: 100%|██████████| 14/14 [00:01<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 (epoch 0), accuracy 31.93%\n",
      "step 10 (epoch 0), loss 0.63\n",
      "step 20 (epoch 0), loss 0.54\n",
      "step 30 (epoch 0), loss 0.43\n",
      "step 40 (epoch 0), loss 0.39\n",
      "step 50 (epoch 0), loss 0.33\n",
      "step 60 (epoch 0), loss 0.28\n",
      "step 70 (epoch 1), loss 0.25\n",
      "step 80 (epoch 1), loss 0.23\n",
      "step 90 (epoch 1), loss 0.21\n",
      "step 100 (epoch 1), loss 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test accuray: 100%|██████████| 14/14 [00:01<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100 (epoch 1), accuracy 98.48%\n",
      "step 110 (epoch 1), loss 0.20\n",
      "step 120 (epoch 1), loss 0.18\n",
      "step 130 (epoch 2), loss 0.17\n",
      "step 140 (epoch 2), loss 0.16\n",
      "step 150 (epoch 2), loss 0.12\n",
      "step 160 (epoch 2), loss 0.12\n",
      "step 170 (epoch 2), loss 0.12\n",
      "step 180 (epoch 2), loss 0.11\n",
      "step 190 (epoch 3), loss 0.09\n",
      "step 200 (epoch 3), loss 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test accuray: 100%|██████████| 14/14 [00:01<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200 (epoch 3), accuracy 99.88%\n",
      "step 210 (epoch 3), loss 0.09\n",
      "step 220 (epoch 3), loss 0.08\n",
      "step 230 (epoch 3), loss 0.08\n",
      "step 240 (epoch 3), loss 0.08\n",
      "step 250 (epoch 4), loss 0.07\n",
      "step 260 (epoch 4), loss 0.08\n",
      "step 270 (epoch 4), loss 0.07\n",
      "step 280 (epoch 4), loss 0.07\n",
      "step 290 (epoch 4), loss 0.07\n",
      "step 300 (epoch 4), loss 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test accuray: 100%|██████████| 14/14 [00:01<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 300 (epoch 4), accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "step = 0\n",
    "\n",
    "for epoch in range(5):\n",
    "    for images, labels in ds_train:\n",
    "        images, labels = images.to(device), torch.Tensor(labels).to(device).long()\n",
    "        logits = model(images)\n",
    "        loss = nn.functional.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        if step % 10 == 0:\n",
    "            print(f\"step {step} (epoch {epoch}), loss {loss.item():.2f}\")\n",
    "        if step % 100 == 0:\n",
    "            model.eval()\n",
    "            acc = test_accuracy(ds_test, model)\n",
    "            print(f\"step {step} (epoch {epoch}), accuracy {acc:.2f}%\")\n",
    "            model.train()\n",
    "    \n",
    "        step += 1\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
